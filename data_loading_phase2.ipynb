{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_loading_phase2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmsamiei/thesis-prototype/blob/master/data_loading_phase2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z34IzmeS7Bd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f1b93cba-70ee-4ac5-ea49-453247c76f92"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fO-sYWD7RBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Thesis/phase-2/tokenized_test.json /content/train.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2dAoag47ZOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import json\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snE8o32EMaO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"My dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, json_file):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            json_file (string): Path to the json file with annotations.\n",
        "        \"\"\"\n",
        "        self.dialogues = json.load(open(json_file))\n",
        "        self.root_dir = json_file\n",
        "\n",
        "        self.dialogues = sorted(self.dialogues, key=lambda x: len(x['history']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dialogues)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        history = torch.LongTensor(self.dialogues[idx]['history'])\n",
        "        true_sample = torch.LongTensor(self.dialogues[idx]['true_sentence'])\n",
        "        false_sample = torch.LongTensor(self.dialogues[idx]['false_sentenc'])\n",
        "\n",
        "        sample = {'history': history, 'true_sample': true_sample, 'false_sample': false_sample}\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1jvtvJNNa4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = MyDataset('train.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9GHeKWPN2R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_collate_fn(batch):\n",
        "\n",
        "  len_batch = len(batch)\n",
        "\n",
        "  padding_ind = 0 ## for bert is 0\n",
        "  max_len_history = max([len(data['history']) for data in batch])\n",
        "  max_len_true_sample = max([len(data['true_sample']) for data in batch])\n",
        "  max_len_false_sample = max([len(data['false_sample']) for data in batch])\n",
        "  \n",
        "  result_history = torch.zeros(len_batch, max_len_history)\n",
        "  result_true_sample = torch.zeros(len_batch, max_len_true_sample)\n",
        "  result_false_sample = torch.zeros(len_batch, max_len_false_sample)\n",
        "\n",
        "  for i, data in enumerate(batch):\n",
        "    p1 = len(data['history'])\n",
        "    result_history[i, :p1] = data['history']\n",
        "    p2 = len(data['true_sample'])\n",
        "    result_true_sample[i, :p2] = data['true_sample']\n",
        "    p3 = len(data['false_sample'])\n",
        "    result_false_sample[i, :p3] = data['false_sample']\n",
        "\n",
        "  return result_history, result_true_sample, result_false_sample  \n",
        "\n",
        "sampler = torch.utils.data.SequentialSampler(dataset)\n",
        "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=2048, sampler=sampler,\n",
        "                                             shuffle=False, collate_fn=my_collate_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4K3dTrGRLc6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5db556a-21cc-472c-c13b-41494ec70e6c"
      },
      "source": [
        "for _, batch in enumerate(dataset_loader):\n",
        "  history, true_sample, false_sample = batch\n",
        "  print(history.shape)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2048, 9])\n",
            "torch.Size([2048, 11])\n",
            "torch.Size([2048, 14])\n",
            "torch.Size([2048, 16])\n",
            "torch.Size([2048, 18])\n",
            "torch.Size([2048, 21])\n",
            "torch.Size([2048, 24])\n",
            "torch.Size([2048, 26])\n",
            "torch.Size([2048, 29])\n",
            "torch.Size([2048, 32])\n",
            "torch.Size([2048, 34])\n",
            "torch.Size([2048, 37])\n",
            "torch.Size([2048, 39])\n",
            "torch.Size([2048, 41])\n",
            "torch.Size([2048, 44])\n",
            "torch.Size([2048, 46])\n",
            "torch.Size([2048, 48])\n",
            "torch.Size([2048, 50])\n",
            "torch.Size([2048, 53])\n",
            "torch.Size([2048, 55])\n",
            "torch.Size([2048, 58])\n",
            "torch.Size([2048, 61])\n",
            "torch.Size([2048, 64])\n",
            "torch.Size([2048, 67])\n",
            "torch.Size([2048, 70])\n",
            "torch.Size([2048, 72])\n",
            "torch.Size([2048, 74])\n",
            "torch.Size([2048, 77])\n",
            "torch.Size([2048, 80])\n",
            "torch.Size([2048, 82])\n",
            "torch.Size([2048, 84])\n",
            "torch.Size([2048, 88])\n",
            "torch.Size([2048, 90])\n",
            "torch.Size([2048, 93])\n",
            "torch.Size([2048, 96])\n",
            "torch.Size([2048, 98])\n",
            "torch.Size([2048, 101])\n",
            "torch.Size([2048, 104])\n",
            "torch.Size([2048, 107])\n",
            "torch.Size([2048, 110])\n",
            "torch.Size([2048, 113])\n",
            "torch.Size([2048, 116])\n",
            "torch.Size([2048, 119])\n",
            "torch.Size([2048, 123])\n",
            "torch.Size([2048, 126])\n",
            "torch.Size([2048, 129])\n",
            "torch.Size([2048, 132])\n",
            "torch.Size([2048, 135])\n",
            "torch.Size([2048, 138])\n",
            "torch.Size([2048, 142])\n",
            "torch.Size([2048, 146])\n",
            "torch.Size([2048, 150])\n",
            "torch.Size([2048, 155])\n",
            "torch.Size([2048, 160])\n",
            "torch.Size([2048, 167])\n",
            "torch.Size([2048, 172])\n",
            "torch.Size([2048, 179])\n",
            "torch.Size([2048, 187])\n",
            "torch.Size([2048, 198])\n",
            "torch.Size([2048, 208])\n",
            "torch.Size([2048, 225])\n",
            "torch.Size([2048, 250])\n",
            "torch.Size([1759, 387])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}