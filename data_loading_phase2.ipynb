{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_loading_phase2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f099bb3bd2d445589f4bc94c8ac44ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a2bdb854f7e4465eb3488898404ee1f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_25d5019c0bec412dab9700d552ad3855",
              "IPY_MODEL_47d3ac4a5a2c40b0a2528e6b55487e58"
            ]
          }
        },
        "a2bdb854f7e4465eb3488898404ee1f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25d5019c0bec412dab9700d552ad3855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5e9e56b9fd2d4f179596ab3625bd650c",
            "_dom_classes": [],
            "description": " 21%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 4023,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 864,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b78da28aa136434a83ac70dcd74b5293"
          }
        },
        "47d3ac4a5a2c40b0a2528e6b55487e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6d584c8ac506477c8e6d13c1b289268e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 864/4023 [00:40&lt;01:13, 43.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88bb7358d5af410c9d170e4b46ba514e"
          }
        },
        "5e9e56b9fd2d4f179596ab3625bd650c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b78da28aa136434a83ac70dcd74b5293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d584c8ac506477c8e6d13c1b289268e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88bb7358d5af410c9d170e4b46ba514e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmsamiei/thesis-prototype/blob/master/data_loading_phase2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z34IzmeS7Bd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f1b93cba-70ee-4ac5-ea49-453247c76f92"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fO-sYWD7RBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Thesis/phase-2/tokenized_test.json /content/train.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2dAoag47ZOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snE8o32EMaO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"My dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, json_file):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            json_file (string): Path to the json file with annotations.\n",
        "        \"\"\"\n",
        "        self.dialogues = json.load(open(json_file))\n",
        "        self.root_dir = json_file\n",
        "\n",
        "        self.dialogues = sorted(self.dialogues, key=lambda x: len(x['history']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dialogues)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "        \n",
        "        history_lst = self.dialogues[idx]['history']\n",
        "        true_lst = self.dialogues[idx]['true_sentence']\n",
        "        false_lst = self.dialogues[idx]['false_sentenc']\n",
        "\n",
        "\n",
        "        if(len(history_lst)>35):\n",
        "          history_lst = history_lst[-35:]\n",
        "\n",
        "        if(len(true_lst)>35):\n",
        "          true_lst = true_lst[:35]\n",
        "        \n",
        "        if(len(false_lst)>35):\n",
        "          false_lst = false_lst[:35]\n",
        "        \n",
        "\n",
        "        history = torch.LongTensor(history_lst)\n",
        "        true_sample = torch.LongTensor(true_lst)\n",
        "        false_sample = torch.LongTensor(false_lst)\n",
        "\n",
        "        sample = {'history': history, 'true_sample': true_sample, 'false_sample': false_sample}\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1jvtvJNNa4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = MyDataset('train.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9GHeKWPN2R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_collate_fn(batch):\n",
        "\n",
        "  len_batch = len(batch)\n",
        "\n",
        "  \n",
        "  max_len_history = max([len(data['history']) for data in batch])\n",
        "  max_len_true_sample = max([len(data['true_sample']) for data in batch])\n",
        "  max_len_false_sample = max([len(data['false_sample']) for data in batch])\n",
        "  \n",
        "  padding_ind = 1 ## for bert is 0 but because embedding hate 0!! we used 1\n",
        "  result_history = torch.ones(len_batch, max_len_history)\n",
        "  result_true_sample = torch.ones(len_batch, max_len_true_sample)\n",
        "  result_false_sample = torch.ones(len_batch, max_len_false_sample)\n",
        "\n",
        "  for i, data in enumerate(batch):\n",
        "    p1 = len(data['history'])\n",
        "    result_history[i, :p1] = data['history']\n",
        "    p2 = len(data['true_sample'])\n",
        "    result_true_sample[i, :p2] = data['true_sample']\n",
        "    p3 = len(data['false_sample'])\n",
        "    result_false_sample[i, :p3] = data['false_sample']\n",
        "\n",
        "\n",
        "\n",
        "  return result_history.T.long(), result_true_sample.T.long(), result_false_sample.T.long()\n",
        "\n",
        "sampler = torch.utils.data.SequentialSampler(dataset)\n",
        "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=32, sampler=sampler,\n",
        "                                             shuffle=False, collate_fn=my_collate_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4K3dTrGRLc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for _, batch in enumerate(dataset_loader):\n",
        "  history, true_sample, false_sample = batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX-DnRE1oqNe",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqsbUH2ZpjkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h82qgzz3pnlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "class RepresentModel(nn.Module):\n",
        "  \n",
        "  def __init__(self, hid_size, vocab_size, n_head, n_layers, pf_size, max_len, device):\n",
        "    super().__init__()\n",
        "\n",
        "    self.device = device\n",
        "    \n",
        "    self.hid_size = hid_size\n",
        "    self.pf_size = pf_size\n",
        "    self.max_len = max_len\n",
        "    self.n_head = n_head\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, hid_size)\n",
        "\n",
        "    self.position_enc = nn.Embedding(self.max_len, self.hid_size)\n",
        "    self.position_enc.weight.data = self.position_encoding_init(self.max_len, self.hid_size)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([self.hid_size])).to(device)\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm(self.hid_size)\n",
        "    self.encoder_layer = nn.TransformerEncoderLayer(d_model=hid_size, nhead = n_head, dim_feedforward = pf_size)\n",
        "    self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=n_layers, norm=self.layer_norm)\n",
        "\n",
        "    self._init_weights()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    sent_len, batch_size = x.shape[0], x.shape[1]\n",
        "\n",
        "    temp = x\n",
        "    temp = self.embedding(temp)\n",
        "\n",
        "    pos = torch.arange(1,sent_len+1).unsqueeze(1).repeat(1,batch_size).to(self.device)\n",
        "    temp_pos_emb = self.position_enc(pos)\n",
        "\n",
        "    temp = temp * self.scale + temp_pos_emb\n",
        "    temp = self.encoder(temp)\n",
        "    temp = temp[0,:]\n",
        "    return temp\n",
        "\n",
        "  def _init_weights(self):\n",
        "    for p in self.parameters():\n",
        "      if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "  def append_decoder_layer(self):\n",
        "    appended_mod = nn.TransformerEncoderLayer(d_model=self.hid_size, nhead = self.n_head, dim_feedforward = self.pf_size).to(self.device)\n",
        "    for p in appended_mod.parameters():\n",
        "      if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "    self.encoder.layers.append(appended_mod)\n",
        "    self.encoder.num_layers += 1\n",
        "\n",
        "  \n",
        "  def position_encoding_init(self, n_position, d_pos_vec):\n",
        "    ''' Init the sinusoid position encoding table '''\n",
        "\n",
        "    # keep dim 0 for padding token position encoding zero vector\n",
        "    position_enc = np.array([\n",
        "        [pos / np.power(10000, 2*i/d_pos_vec) for i in range(d_pos_vec)]\n",
        "        if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
        "\n",
        "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
        "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
        "    temp = torch.from_numpy(position_enc).type(torch.FloatTensor)\n",
        "    temp = temp.to(self.device)\n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96xP1nkwqBF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hid_size = 16\n",
        "vocab_size = 34000 \n",
        "n_head = 8\n",
        "n_layers = 1\n",
        "pf_size = 32\n",
        "max_len = 500\n",
        "model = RepresentModel(hid_size, vocab_size, n_head, n_layers, pf_size, max_len, device).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBxaJoPYzKKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "126990d9-c098-40cf-a544-48c01e443196"
      },
      "source": [
        "test_len = 20\n",
        "batch_size = 64\n",
        "test_input = torch.LongTensor(test_len, batch_size).random_(1,vocab_size).to(device)\n",
        "model(test_input).shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_2B7BDDzeSb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ccbaf8e8-60f9-499a-d2c1-a6eebff5d5c9"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 556,480 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5WcpXG2zuze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NoamOpt:\n",
        "    \"Optim wrapper that implements rate.\"\n",
        "    def __init__(self, model_size, factor, warmup, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.model_size = model_size\n",
        "        self._rate = 0\n",
        "        \n",
        "    def step(self):\n",
        "        \"Update parameters and rate\"\n",
        "        self._step += 1\n",
        "        rate = self.rate()\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def rate(self, step = None):\n",
        "        \"Implement `lrate` above\"\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        return self.factor * \\\n",
        "            (self.model_size ** (-0.5) *\n",
        "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
        "    \n",
        "    def zero_grad(self):\n",
        "        self.optimizer.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxCNVda75vCN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "95444345-08c3-4368-b7a5-bd4c28f104a8"
      },
      "source": [
        "!pip install -U tqdm"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHXTmePhzvs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train_one_epoch(model,train_iter, optimizer, criterion, clip):\n",
        "  epoch_loss = 0\n",
        "  model.train()\n",
        "  for batch in tqdm(train_iter):\n",
        "    optimizer.zero_grad()\n",
        "    history, true_sample, false_sample = batch\n",
        "    batch_size = history.shape[1]\n",
        "    ### hist = [sent_len, batch]\n",
        "    history_rpr = model(history.to(device))\n",
        "    true_rpr = model(true_sample.to(device))\n",
        "    false_rpr = model(false_sample.to(device))\n",
        "    ## rpr = [batch_size, hidden]\n",
        "    cos = nn.PairwiseDistance().to(device)\n",
        "    tru_sml = -1*cos(history_rpr, true_rpr)\n",
        "    fls_sml = -1*cos(history_rpr, false_rpr)\n",
        "    mini_batch_tensor = torch.ones(batch_size).to(device)\n",
        "    loss = criterion(tru_sml, fls_sml, mini_batch_tensor)\n",
        "    print(history.shape[0], true_sample.shape[0], false_sample.shape[0])\n",
        "    print(loss.item())\n",
        "    loss.backward()\n",
        "    epoch_loss += loss\n",
        "  return epoch_loss / len(train_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvL0qeLD1ebH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_iter, optimizer, criterion, clip, N_EPOCH):\n",
        "  for epoch in range(N_EPOCH):\n",
        "    epoch_loss = train_one_epoch(model, train_iter, optimizer, criterion, clip)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QHqzH9x1kL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f099bb3bd2d445589f4bc94c8ac44ef",
            "a2bdb854f7e4465eb3488898404ee1f7",
            "25d5019c0bec412dab9700d552ad3855",
            "47d3ac4a5a2c40b0a2528e6b55487e58",
            "5e9e56b9fd2d4f179596ab3625bd650c",
            "b78da28aa136434a83ac70dcd74b5293",
            "6d584c8ac506477c8e6d13c1b289268e",
            "88bb7358d5af410c9d170e4b46ba514e"
          ]
        },
        "outputId": "f3a7e6c0-f57f-45a8-ae84-afa01ef57c12"
      },
      "source": [
        "optimizer = NoamOpt(hid_size, 1, 2000,\n",
        "              torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "criterion = torch.nn.MarginRankingLoss(margin=1).to(device)\n",
        "train(model, dataset_loader, optimizer, criterion, 1, 1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f099bb3bd2d445589f4bc94c8ac44ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4023.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3 52 67\n",
            "0.6460055708885193\n",
            "3 52 56\n",
            "1.054274559020996\n",
            "5 52 62\n",
            "0.7019585371017456\n",
            "5 52 75\n",
            "0.8209887742996216\n",
            "6 34 87\n",
            "0.9983526468276978\n",
            "6 33 81\n",
            "0.7971975803375244\n",
            "6 43 80\n",
            "0.8814077377319336\n",
            "6 43 61\n",
            "0.9948355555534363\n",
            "6 35 57\n",
            "1.0315334796905518\n",
            "6 27 50\n",
            "0.831860363483429\n",
            "6 32 71\n",
            "0.8117556571960449\n",
            "7 37 85\n",
            "0.7745225429534912\n",
            "7 37 91\n",
            "0.9712182283401489\n",
            "7 39 65\n",
            "0.9871038198471069\n",
            "8 46 49\n",
            "0.7969189882278442\n",
            "8 52 80\n",
            "0.7927400469779968\n",
            "8 52 91\n",
            "0.9067511558532715\n",
            "8 95 68\n",
            "0.9709776043891907\n",
            "8 95 69\n",
            "0.802191972732544\n",
            "8 33 84\n",
            "0.7575780153274536\n",
            "8 48 86\n",
            "0.876212477684021\n",
            "8 48 81\n",
            "0.6301506757736206\n",
            "8 48 105\n",
            "0.5902564525604248\n",
            "8 40 60\n",
            "0.9121924042701721\n",
            "8 52 114\n",
            "0.6895809173583984\n",
            "8 52 99\n",
            "0.7835640907287598\n",
            "8 60 65\n",
            "0.8980699777603149\n",
            "8 60 71\n",
            "0.9852886199951172\n",
            "8 58 70\n",
            "0.9208000302314758\n",
            "8 58 68\n",
            "0.9007561802864075\n",
            "8 35 53\n",
            "0.8275817632675171\n",
            "8 27 46\n",
            "0.9727283716201782\n",
            "8 31 69\n",
            "0.7444924116134644\n",
            "8 48 77\n",
            "0.704339861869812\n",
            "8 48 51\n",
            "0.6901280879974365\n",
            "8 44 70\n",
            "0.7601829767227173\n",
            "8 44 60\n",
            "1.0590320825576782\n",
            "8 48 62\n",
            "0.8467715978622437\n",
            "8 48 102\n",
            "0.9035362005233765\n",
            "9 69 104\n",
            "0.890859842300415\n",
            "9 69 66\n",
            "0.8982254266738892\n",
            "9 27 74\n",
            "0.9004149436950684\n",
            "9 60 75\n",
            "0.9756598472595215\n",
            "9 60 53\n",
            "0.8772931694984436\n",
            "9 46 70\n",
            "1.0392262935638428\n",
            "9 46 60\n",
            "0.7788678407669067\n",
            "9 37 77\n",
            "1.0518290996551514\n",
            "9 37 115\n",
            "0.9459382891654968\n",
            "9 47 82\n",
            "0.8638335466384888\n",
            "9 47 91\n",
            "0.7793150544166565\n",
            "9 40 107\n",
            "0.8124097585678101\n",
            "9 40 86\n",
            "0.7647868990898132\n",
            "9 42 45\n",
            "0.9393695592880249\n",
            "9 42 117\n",
            "0.8474446535110474\n",
            "9 51 67\n",
            "0.9095579385757446\n",
            "9 51 77\n",
            "1.0051679611206055\n",
            "9 39 62\n",
            "0.7965211868286133\n",
            "9 39 74\n",
            "0.8419163227081299\n",
            "9 48 62\n",
            "0.8913005590438843\n",
            "9 59 74\n",
            "0.9723360538482666\n",
            "9 59 47\n",
            "0.8020757436752319\n",
            "9 40 114\n",
            "0.8185875415802002\n",
            "9 61 67\n",
            "0.9331856966018677\n",
            "9 61 77\n",
            "0.8636115193367004\n",
            "9 45 62\n",
            "0.8248038291931152\n",
            "9 58 61\n",
            "0.9126391410827637\n",
            "9 58 88\n",
            "0.8163967132568359\n",
            "9 38 76\n",
            "0.718982458114624\n",
            "9 41 114\n",
            "0.8629287481307983\n",
            "9 66 91\n",
            "0.8933232426643372\n",
            "9 66 62\n",
            "1.1045284271240234\n",
            "9 58 66\n",
            "0.94219970703125\n",
            "9 58 71\n",
            "0.8520138263702393\n",
            "9 49 98\n",
            "0.6816666126251221\n",
            "9 33 63\n",
            "0.989334762096405\n",
            "9 72 97\n",
            "0.8023426532745361\n",
            "9 36 78\n",
            "0.9314886927604675\n",
            "9 78 75\n",
            "1.0201377868652344\n",
            "9 78 61\n",
            "0.9455132484436035\n",
            "9 47 202\n",
            "0.7088445425033569\n",
            "9 47 44\n",
            "1.1487774848937988\n",
            "10 67 66\n",
            "1.0839405059814453\n",
            "10 67 81\n",
            "0.8960710763931274\n",
            "10 49 61\n",
            "0.9087342023849487\n",
            "10 67 77\n",
            "0.9920526146888733\n",
            "10 67 91\n",
            "0.6743046045303345\n",
            "10 107 66\n",
            "0.8448405265808105\n",
            "10 107 67\n",
            "1.0120649337768555\n",
            "10 48 73\n",
            "0.8634821176528931\n",
            "10 48 56\n",
            "0.9077655076980591\n",
            "10 43 76\n",
            "0.7762166261672974\n",
            "10 43 135\n",
            "0.8484348058700562\n",
            "10 50 77\n",
            "0.7852013111114502\n",
            "10 50 57\n",
            "0.862089991569519\n",
            "10 50 71\n",
            "0.7711944580078125\n",
            "10 50 55\n",
            "0.9196192622184753\n",
            "10 49 71\n",
            "0.7891181707382202\n",
            "10 49 48\n",
            "1.035512089729309\n",
            "10 55 73\n",
            "1.0296066999435425\n",
            "10 55 63\n",
            "1.0285212993621826\n",
            "10 54 52\n",
            "0.9306939840316772\n",
            "10 36 128\n",
            "0.8289290070533752\n",
            "10 35 54\n",
            "0.9175784587860107\n",
            "10 45 70\n",
            "0.9430018663406372\n",
            "10 45 121\n",
            "0.7433105111122131\n",
            "10 22 82\n",
            "0.784973680973053\n",
            "10 41 60\n",
            "0.9284733533859253\n",
            "10 41 80\n",
            "0.8490416407585144\n",
            "11 55 79\n",
            "0.9441695809364319\n",
            "11 55 57\n",
            "1.0176353454589844\n",
            "11 69 65\n",
            "0.8108649849891663\n",
            "11 69 46\n",
            "0.9373016357421875\n",
            "11 38 77\n",
            "0.796728789806366\n",
            "11 38 86\n",
            "0.8328783512115479\n",
            "11 42 72\n",
            "0.8199557662010193\n",
            "11 42 56\n",
            "0.8316009044647217\n",
            "11 40 69\n",
            "0.8315666913986206\n",
            "11 36 89\n",
            "0.63849937915802\n",
            "11 44 88\n",
            "0.8489379286766052\n",
            "11 44 76\n",
            "0.8239955902099609\n",
            "11 35 152\n",
            "0.8875040411949158\n",
            "11 27 49\n",
            "0.965904176235199\n",
            "11 61 61\n",
            "1.0733895301818848\n",
            "11 61 63\n",
            "0.9978857040405273\n",
            "11 61 99\n",
            "0.8245809078216553\n",
            "11 38 53\n",
            "0.9115935564041138\n",
            "11 39 84\n",
            "0.7071695327758789\n",
            "11 40 56\n",
            "0.9295151233673096\n",
            "11 40 47\n",
            "0.8637173771858215\n",
            "11 30 62\n",
            "0.8619768023490906\n",
            "11 33 67\n",
            "0.8244035243988037\n",
            "11 46 74\n",
            "0.8312428593635559\n",
            "11 68 41\n",
            "0.9692710041999817\n",
            "12 68 71\n",
            "0.9238031506538391\n",
            "12 51 55\n",
            "0.9097961187362671\n",
            "12 61 59\n",
            "0.9390236139297485\n",
            "12 61 59\n",
            "1.1391093730926514\n",
            "12 76 67\n",
            "1.1146092414855957\n",
            "12 76 91\n",
            "0.9187988042831421\n",
            "12 68 53\n",
            "0.8437552452087402\n",
            "12 68 78\n",
            "0.8955346345901489\n",
            "12 47 54\n",
            "0.8863437175750732\n",
            "12 42 79\n",
            "0.723520040512085\n",
            "12 29 71\n",
            "0.6800531148910522\n",
            "12 37 63\n",
            "0.8007740378379822\n",
            "12 48 77\n",
            "0.7699360847473145\n",
            "12 48 62\n",
            "0.7218149304389954\n",
            "12 46 55\n",
            "0.84947270154953\n",
            "12 46 62\n",
            "0.9914336800575256\n",
            "12 46 55\n",
            "0.8549231886863708\n",
            "12 59 69\n",
            "0.7441884279251099\n",
            "12 59 54\n",
            "1.0526399612426758\n",
            "13 35 135\n",
            "0.6677343249320984\n",
            "13 40 70\n",
            "0.7772812247276306\n",
            "13 40 67\n",
            "0.6926339864730835\n",
            "13 47 81\n",
            "0.8388645052909851\n",
            "13 47 75\n",
            "0.8299840688705444\n",
            "13 47 65\n",
            "0.8009181618690491\n",
            "13 47 60\n",
            "0.9144591093063354\n",
            "13 47 61\n",
            "0.75004643201828\n",
            "13 45 101\n",
            "0.9060573577880859\n",
            "13 60 175\n",
            "0.6162192821502686\n",
            "13 60 65\n",
            "0.9480050802230835\n",
            "13 38 63\n",
            "0.7671972513198853\n",
            "13 38 97\n",
            "0.7231549620628357\n",
            "13 57 102\n",
            "0.7242138385772705\n",
            "13 57 65\n",
            "0.6974590420722961\n",
            "13 41 76\n",
            "0.7767135500907898\n",
            "13 72 59\n",
            "1.0916281938552856\n",
            "13 72 64\n",
            "0.8571254014968872\n",
            "13 65 53\n",
            "0.8648148775100708\n",
            "13 39 70\n",
            "0.8327741622924805\n",
            "13 42 73\n",
            "0.9342834949493408\n",
            "13 42 78\n",
            "0.8052971959114075\n",
            "13 45 95\n",
            "0.8577867746353149\n",
            "13 45 104\n",
            "0.5710277557373047\n",
            "13 45 63\n",
            "0.6899205446243286\n",
            "13 84 92\n",
            "0.8149902820587158\n",
            "14 84 92\n",
            "1.045549988746643\n",
            "14 46 45\n",
            "0.9744019508361816\n",
            "14 63 55\n",
            "0.9481261968612671\n",
            "14 63 57\n",
            "0.8468304872512817\n",
            "14 43 101\n",
            "0.804990291595459\n",
            "14 50 57\n",
            "0.7534481287002563\n",
            "14 50 60\n",
            "0.7715727090835571\n",
            "14 41 55\n",
            "0.9927656054496765\n",
            "14 41 72\n",
            "0.7777173519134521\n",
            "14 72 120\n",
            "0.6287618279457092\n",
            "14 72 62\n",
            "0.9421643018722534\n",
            "14 45 55\n",
            "0.8567752242088318\n",
            "14 43 76\n",
            "0.7571073174476624\n",
            "14 51 63\n",
            "0.832086980342865\n",
            "14 69 65\n",
            "0.8965462446212769\n",
            "14 70 81\n",
            "0.5940414071083069\n",
            "14 70 71\n",
            "0.821120023727417\n",
            "14 34 80\n",
            "0.7720721364021301\n",
            "14 32 59\n",
            "0.8673417568206787\n",
            "14 44 49\n",
            "0.7935910224914551\n",
            "14 47 65\n",
            "0.6092156767845154\n",
            "14 47 61\n",
            "0.8027758598327637\n",
            "14 47 108\n",
            "0.8534268736839294\n",
            "14 35 72\n",
            "0.8375810384750366\n",
            "14 48 59\n",
            "0.7783179879188538\n",
            "14 52 74\n",
            "0.7635849714279175\n",
            "14 80 88\n",
            "0.7756026983261108\n",
            "14 80 91\n",
            "0.7934224605560303\n",
            "14 66 77\n",
            "0.7784997224807739\n",
            "14 43 119\n",
            "0.7443393468856812\n",
            "14 48 57\n",
            "0.8382807970046997\n",
            "14 48 57\n",
            "0.9306398034095764\n",
            "14 77 104\n",
            "0.9633843898773193\n",
            "14 77 84\n",
            "0.7214968204498291\n",
            "14 65 90\n",
            "0.9264847636222839\n",
            "15 42 78\n",
            "0.9049645662307739\n",
            "15 40 68\n",
            "0.9716812372207642\n",
            "15 35 76\n",
            "0.779655396938324\n",
            "15 70 71\n",
            "1.0457470417022705\n",
            "15 70 71\n",
            "0.9290754199028015\n",
            "15 50 61\n",
            "0.6857163906097412\n",
            "15 42 72\n",
            "0.8146432638168335\n",
            "15 40 70\n",
            "0.5430126190185547\n",
            "15 40 56\n",
            "0.6704089045524597\n",
            "15 38 53\n",
            "1.0245277881622314\n",
            "15 38 63\n",
            "0.8344635367393494\n",
            "15 48 72\n",
            "0.8050433397293091\n",
            "15 35 68\n",
            "0.8161780834197998\n",
            "15 35 55\n",
            "0.842071533203125\n",
            "15 35 76\n",
            "0.9188553094863892\n",
            "15 59 105\n",
            "0.9489388465881348\n",
            "15 59 52\n",
            "0.9424494504928589\n",
            "15 34 48\n",
            "0.8741381764411926\n",
            "15 34 52\n",
            "0.9417226314544678\n",
            "15 36 59\n",
            "0.829220175743103\n",
            "15 62 51\n",
            "0.9804831743240356\n",
            "15 70 62\n",
            "0.8568254709243774\n",
            "15 70 66\n",
            "0.8188058137893677\n",
            "15 63 51\n",
            "0.7720866203308105\n",
            "15 56 48\n",
            "0.9497064352035522\n",
            "15 56 62\n",
            "0.8714552521705627\n",
            "15 75 71\n",
            "0.9039483666419983\n",
            "15 75 53\n",
            "1.0703294277191162\n",
            "15 50 75\n",
            "0.8298319578170776\n",
            "15 42 62\n",
            "0.7872889041900635\n",
            "15 42 74\n",
            "0.6361407041549683\n",
            "15 42 76\n",
            "0.8644141554832458\n",
            "15 31 114\n",
            "0.7175091505050659\n",
            "16 39 60\n",
            "0.7790572643280029\n",
            "16 39 68\n",
            "0.8806852102279663\n",
            "16 44 87\n",
            "0.7734076380729675\n",
            "16 44 57\n",
            "0.8544480204582214\n",
            "16 43 70\n",
            "0.8872400522232056\n",
            "16 74 119\n",
            "0.6663186550140381\n",
            "16 74 66\n",
            "1.072104573249817\n",
            "16 47 81\n",
            "0.7968963384628296\n",
            "16 47 65\n",
            "0.8453004360198975\n",
            "16 40 58\n",
            "0.6899319291114807\n",
            "16 40 48\n",
            "0.8748681545257568\n",
            "16 44 63\n",
            "1.0377395153045654\n",
            "16 44 51\n",
            "0.8631305694580078\n",
            "16 44 79\n",
            "0.8122819662094116\n",
            "16 41 167\n",
            "0.6301383972167969\n",
            "16 41 59\n",
            "0.9858946800231934\n",
            "16 40 120\n",
            "0.7762123942375183\n",
            "16 45 61\n",
            "0.9057732820510864\n",
            "16 45 119\n",
            "0.7855592966079712\n",
            "16 41 69\n",
            "0.9421910643577576\n",
            "16 41 77\n",
            "0.820943295955658\n",
            "16 38 53\n",
            "0.8089900612831116\n",
            "16 44 97\n",
            "0.6880484819412231\n",
            "16 36 59\n",
            "0.8528662323951721\n",
            "16 36 81\n",
            "0.7871284484863281\n",
            "16 76 73\n",
            "0.9835789203643799\n",
            "16 76 53\n",
            "1.0368038415908813\n",
            "16 57 69\n",
            "0.5681131482124329\n",
            "16 55 56\n",
            "0.8387755155563354\n",
            "16 55 66\n",
            "0.7164521217346191\n",
            "16 50 75\n",
            "0.6600686311721802\n",
            "17 59 52\n",
            "0.9107057452201843\n",
            "17 59 76\n",
            "0.9404903650283813\n",
            "17 41 75\n",
            "0.6874308586120605\n",
            "17 51 85\n",
            "0.6327230930328369\n",
            "17 51 76\n",
            "0.7558350563049316\n",
            "17 49 50\n",
            "0.8124343156814575\n",
            "17 60 64\n",
            "1.017874836921692\n",
            "17 60 61\n",
            "1.0160658359527588\n",
            "17 33 77\n",
            "0.7164543867111206\n",
            "17 39 70\n",
            "0.8689481019973755\n",
            "17 39 68\n",
            "0.7994871139526367\n",
            "17 34 75\n",
            "0.8082047700881958\n",
            "17 48 158\n",
            "0.9629217386245728\n",
            "17 48 79\n",
            "0.8170942068099976\n",
            "17 38 62\n",
            "0.9816494584083557\n",
            "17 38 71\n",
            "0.8129682540893555\n",
            "17 38 64\n",
            "0.9584207534790039\n",
            "17 38 73\n",
            "0.8691374063491821\n",
            "17 49 66\n",
            "0.8687782287597656\n",
            "17 49 61\n",
            "0.8676401376724243\n",
            "17 45 61\n",
            "0.8202781677246094\n",
            "17 36 63\n",
            "0.7473909258842468\n",
            "17 92 63\n",
            "0.8946762084960938\n",
            "17 92 104\n",
            "0.8518823385238647\n",
            "17 65 68\n",
            "1.007444143295288\n",
            "17 65 79\n",
            "0.7886160612106323\n",
            "18 50 79\n",
            "0.9997254610061646\n",
            "18 46 94\n",
            "0.6291782855987549\n",
            "18 56 71\n",
            "1.0238170623779297\n",
            "18 56 79\n",
            "0.7969738245010376\n",
            "18 62 86\n",
            "0.8306928277015686\n",
            "18 62 79\n",
            "0.6299376487731934\n",
            "18 31 53\n",
            "0.7967394590377808\n",
            "18 57 80\n",
            "0.9404692649841309\n",
            "18 57 96\n",
            "0.7699533700942993\n",
            "18 26 66\n",
            "0.5479990243911743\n",
            "18 47 68\n",
            "0.7284008264541626\n",
            "18 47 89\n",
            "0.7941609025001526\n",
            "18 52 82\n",
            "1.0358065366744995\n",
            "18 52 66\n",
            "0.8309715986251831\n",
            "18 52 74\n",
            "0.8525676727294922\n",
            "18 72 56\n",
            "1.0449650287628174\n",
            "18 72 48\n",
            "1.007384181022644\n",
            "18 50 66\n",
            "0.8390953540802002\n",
            "18 50 87\n",
            "0.7554655075073242\n",
            "18 43 61\n",
            "1.0989325046539307\n",
            "18 38 60\n",
            "0.8053059577941895\n",
            "18 46 111\n",
            "0.7893505692481995\n",
            "18 46 75\n",
            "0.8919755816459656\n",
            "18 27 96\n",
            "0.6192384958267212\n",
            "18 47 60\n",
            "0.9720762968063354\n",
            "18 52 66\n",
            "0.7739384770393372\n",
            "18 52 72\n",
            "0.820592999458313\n",
            "18 34 65\n",
            "0.8394341468811035\n",
            "19 46 86\n",
            "0.7237269878387451\n",
            "19 38 60\n",
            "0.9514750838279724\n",
            "19 50 91\n",
            "0.9295635223388672\n",
            "19 50 68\n",
            "0.8796610236167908\n",
            "19 41 65\n",
            "0.8425005674362183\n",
            "19 62 69\n",
            "0.8532435894012451\n",
            "19 62 60\n",
            "0.8678978681564331\n",
            "19 54 66\n",
            "0.7953468561172485\n",
            "19 54 70\n",
            "0.8728758096694946\n",
            "19 38 50\n",
            "0.9157061576843262\n",
            "19 38 69\n",
            "0.8244893550872803\n",
            "19 54 75\n",
            "0.7690445184707642\n",
            "19 54 64\n",
            "0.9257653951644897\n",
            "19 38 79\n",
            "0.6882383823394775\n",
            "19 55 69\n",
            "0.8240156173706055\n",
            "19 55 50\n",
            "0.787792444229126\n",
            "19 36 80\n",
            "0.7931450605392456\n",
            "20 60 73\n",
            "0.8536257743835449\n",
            "20 60 69\n",
            "0.8843797445297241\n",
            "20 52 66\n",
            "0.8488330245018005\n",
            "20 88 65\n",
            "0.9283434152603149\n",
            "20 88 64\n",
            "0.9389920234680176\n",
            "20 59 51\n",
            "0.9805994629859924\n",
            "20 53 109\n",
            "0.9066459536552429\n",
            "20 41 63\n",
            "0.6189283132553101\n",
            "20 41 54\n",
            "1.0376276969909668\n",
            "20 81 70\n",
            "1.0946338176727295\n",
            "20 81 51\n",
            "0.9727079272270203\n",
            "20 34 72\n",
            "0.8793970942497253\n",
            "20 33 55\n",
            "0.9211857318878174\n",
            "20 58 68\n",
            "0.7029253840446472\n",
            "20 58 67\n",
            "0.9149616956710815\n",
            "20 38 51\n",
            "0.9611026644706726\n",
            "20 38 80\n",
            "0.759496808052063\n",
            "20 31 70\n",
            "0.8783776760101318\n",
            "20 31 52\n",
            "0.7208434343338013\n",
            "20 43 134\n",
            "0.9387357831001282\n",
            "20 51 55\n",
            "0.8666549921035767\n",
            "20 51 94\n",
            "0.6397615671157837\n",
            "20 63 56\n",
            "0.9785441160202026\n",
            "20 63 60\n",
            "0.7807850241661072\n",
            "20 50 71\n",
            "0.8998401165008545\n",
            "20 45 46\n",
            "0.9858139157295227\n",
            "20 45 62\n",
            "0.9663800001144409\n",
            "20 29 78\n",
            "0.7831012606620789\n",
            "20 35 99\n",
            "0.8672969341278076\n",
            "20 69 86\n",
            "0.9892084002494812\n",
            "21 69 80\n",
            "0.8027388453483582\n",
            "21 67 59\n",
            "0.9079563617706299\n",
            "21 56 135\n",
            "0.6409825682640076\n",
            "21 40 78\n",
            "0.6471830010414124\n",
            "21 51 75\n",
            "0.8943530321121216\n",
            "21 51 52\n",
            "0.6916016936302185\n",
            "21 51 56\n",
            "0.8967772722244263\n",
            "21 58 65\n",
            "0.8772782683372498\n",
            "21 58 60\n",
            "1.0957400798797607\n",
            "21 83 79\n",
            "1.052443265914917\n",
            "21 83 74\n",
            "0.8795634508132935\n",
            "21 76 98\n",
            "0.8857440948486328\n",
            "21 76 58\n",
            "1.0188183784484863\n",
            "21 45 73\n",
            "0.7913883924484253\n",
            "21 52 75\n",
            "0.7742816209793091\n",
            "21 52 55\n",
            "0.8628820180892944\n",
            "21 32 151\n",
            "0.6876692771911621\n",
            "21 41 114\n",
            "0.7490689754486084\n",
            "21 44 42\n",
            "1.0562483072280884\n",
            "21 44 63\n",
            "0.9287188053131104\n",
            "21 33 67\n",
            "0.8477550148963928\n",
            "21 50 79\n",
            "1.0264674425125122\n",
            "21 50 56\n",
            "0.809594988822937\n",
            "22 67 79\n",
            "0.9503993988037109\n",
            "22 67 79\n",
            "0.935616135597229\n",
            "22 96 118\n",
            "0.7983949184417725\n",
            "22 96 82\n",
            "0.9398805499076843\n",
            "22 59 69\n",
            "0.9384019374847412\n",
            "22 59 58\n",
            "0.8948745131492615\n",
            "22 48 56\n",
            "0.8510883450508118\n",
            "22 48 53\n",
            "0.8111786842346191\n",
            "22 34 42\n",
            "0.8802346587181091\n",
            "22 53 74\n",
            "0.7687352895736694\n",
            "22 53 66\n",
            "0.9419105052947998\n",
            "22 53 78\n",
            "0.8506244421005249\n",
            "22 93 76\n",
            "1.1001653671264648\n",
            "22 93 99\n",
            "0.9517822265625\n",
            "22 42 62\n",
            "0.7017480134963989\n",
            "22 42 74\n",
            "0.7894806861877441\n",
            "22 43 85\n",
            "0.8174972534179688\n",
            "22 43 93\n",
            "0.7500588893890381\n",
            "22 40 72\n",
            "0.8358275890350342\n",
            "22 44 57\n",
            "0.9290624260902405\n",
            "22 44 71\n",
            "0.7968576550483704\n",
            "22 53 73\n",
            "0.8981966972351074\n",
            "22 53 95\n",
            "0.7018749713897705\n",
            "22 53 50\n",
            "0.9011325240135193\n",
            "22 36 79\n",
            "0.6800320148468018\n",
            "22 54 57\n",
            "0.9004135727882385\n",
            "22 54 65\n",
            "0.7974148392677307\n",
            "23 93 70\n",
            "0.7885002493858337\n",
            "23 93 144\n",
            "0.6503564715385437\n",
            "23 32 62\n",
            "1.0534850358963013\n",
            "23 34 67\n",
            "0.8703522682189941\n",
            "23 34 60\n",
            "0.8776832222938538\n",
            "23 32 63\n",
            "0.8225243091583252\n",
            "23 30 48\n",
            "0.9300504922866821\n",
            "23 30 56\n",
            "0.7950248718261719\n",
            "23 41 80\n",
            "0.8130134344100952\n",
            "23 35 72\n",
            "0.75242680311203\n",
            "23 41 129\n",
            "0.935512363910675\n",
            "23 64 61\n",
            "1.087713599205017\n",
            "23 64 52\n",
            "0.9564168453216553\n",
            "23 70 73\n",
            "0.8630630970001221\n",
            "23 70 80\n",
            "0.9887484908103943\n",
            "23 65 110\n",
            "0.7904558777809143\n",
            "23 65 93\n",
            "0.80172199010849\n",
            "23 54 119\n",
            "0.7435694932937622\n",
            "23 35 71\n",
            "0.7918322086334229\n",
            "24 30 75\n",
            "0.9419916868209839\n",
            "24 42 79\n",
            "0.7861575484275818\n",
            "24 48 65\n",
            "0.8152456283569336\n",
            "24 48 56\n",
            "1.0186443328857422\n",
            "24 60 50\n",
            "0.9934446811676025\n",
            "24 60 71\n",
            "0.7034177780151367\n",
            "24 90 49\n",
            "0.9594748020172119\n",
            "24 90 64\n",
            "1.0747133493423462\n",
            "24 67 67\n",
            "0.9940617680549622\n",
            "24 67 68\n",
            "0.8451234698295593\n",
            "24 62 71\n",
            "0.8973523378372192\n",
            "24 38 56\n",
            "0.8582080006599426\n",
            "24 52 91\n",
            "0.7407979369163513\n",
            "24 52 61\n",
            "0.8389652371406555\n",
            "24 47 75\n",
            "0.9008027911186218\n",
            "24 53 90\n",
            "0.8339425325393677\n",
            "24 73 56\n",
            "0.8465883731842041\n",
            "24 73 58\n",
            "0.8082131147384644\n",
            "24 73 80\n",
            "1.0557503700256348\n",
            "24 33 85\n",
            "0.7310805916786194\n",
            "24 40 76\n",
            "0.7903631925582886\n",
            "24 40 121\n",
            "0.5535926818847656\n",
            "24 39 72\n",
            "0.7791202068328857\n",
            "24 37 87\n",
            "0.9121886491775513\n",
            "24 52 86\n",
            "0.9357848763465881\n",
            "24 53 75\n",
            "0.8594956398010254\n",
            "24 53 60\n",
            "0.7635995745658875\n",
            "25 48 80\n",
            "0.9609073400497437\n",
            "25 63 75\n",
            "0.9247230291366577\n",
            "25 63 63\n",
            "0.8644834756851196\n",
            "25 38 81\n",
            "0.9219542741775513\n",
            "25 90 82\n",
            "0.9187710881233215\n",
            "25 90 51\n",
            "1.1391805410385132\n",
            "25 33 80\n",
            "0.6875161528587341\n",
            "25 48 110\n",
            "0.9582858681678772\n",
            "25 65 70\n",
            "0.8517872095108032\n",
            "25 65 99\n",
            "0.9327149987220764\n",
            "25 60 64\n",
            "0.7982917428016663\n",
            "25 60 80\n",
            "0.9304381012916565\n",
            "25 44 87\n",
            "0.7586174607276917\n",
            "25 47 180\n",
            "0.7073220014572144\n",
            "25 47 66\n",
            "0.9644529223442078\n",
            "25 36 50\n",
            "1.0312690734863281\n",
            "25 52 60\n",
            "0.896384596824646\n",
            "25 52 80\n",
            "0.7597112655639648\n",
            "25 31 62\n",
            "0.6691471934318542\n",
            "25 24 72\n",
            "0.8781347274780273\n",
            "25 30 135\n",
            "0.596904993057251\n",
            "25 30 64\n",
            "0.8790115118026733\n",
            "25 28 60\n",
            "0.9887552261352539\n",
            "25 32 78\n",
            "0.9079219698905945\n",
            "26 39 93\n",
            "0.7539244890213013\n",
            "26 39 89\n",
            "0.8404258489608765\n",
            "26 59 89\n",
            "0.9569106698036194\n",
            "26 59 74\n",
            "1.00411057472229\n",
            "26 54 83\n",
            "0.8955405354499817\n",
            "26 54 61\n",
            "0.9187333583831787\n",
            "26 41 72\n",
            "0.9714655876159668\n",
            "26 75 86\n",
            "0.6218298077583313\n",
            "26 75 47\n",
            "0.9328474998474121\n",
            "26 54 83\n",
            "0.6986597776412964\n",
            "26 39 65\n",
            "0.7498691082000732\n",
            "26 39 88\n",
            "0.6951781511306763\n",
            "26 39 49\n",
            "0.8456605672836304\n",
            "26 59 68\n",
            "0.7355965375900269\n",
            "26 59 46\n",
            "1.2125951051712036\n",
            "26 51 78\n",
            "0.8301818370819092\n",
            "26 51 139\n",
            "0.8827835321426392\n",
            "26 39 67\n",
            "0.8035159111022949\n",
            "26 38 99\n",
            "0.7006195783615112\n",
            "26 43 114\n",
            "0.8019780516624451\n",
            "26 71 133\n",
            "0.8092200756072998\n",
            "26 71 67\n",
            "0.9074656963348389\n",
            "27 76 55\n",
            "1.12576425075531\n",
            "27 76 83\n",
            "0.716018557548523\n",
            "27 49 89\n",
            "0.7809324264526367\n",
            "27 49 73\n",
            "0.8241856694221497\n",
            "27 49 135\n",
            "0.9058517813682556\n",
            "27 49 59\n",
            "0.7275822162628174\n",
            "27 49 81\n",
            "0.6741296648979187\n",
            "27 48 60\n",
            "0.7385050058364868\n",
            "27 49 63\n",
            "0.7627962827682495\n",
            "27 49 76\n",
            "0.8662875294685364\n",
            "27 43 89\n",
            "0.6669235229492188\n",
            "27 66 57\n",
            "1.0512781143188477\n",
            "27 66 70\n",
            "0.8118273019790649\n",
            "27 52 111\n",
            "0.6907179355621338\n",
            "27 62 60\n",
            "0.9586423635482788\n",
            "27 62 79\n",
            "0.7562845945358276\n",
            "27 40 69\n",
            "0.8820054531097412\n",
            "27 29 69\n",
            "0.7399381399154663\n",
            "27 82 57\n",
            "0.9177759289741516\n",
            "27 82 66\n",
            "1.1877639293670654\n",
            "27 69 83\n",
            "0.6811533570289612\n",
            "28 67 69\n",
            "0.9067981243133545\n",
            "28 67 72\n",
            "0.9652122259140015\n",
            "28 66 69\n",
            "0.8644416332244873\n",
            "28 66 121\n",
            "0.6525765061378479\n",
            "28 66 55\n",
            "1.095353364944458\n",
            "28 34 119\n",
            "0.5454698801040649\n",
            "28 60 64\n",
            "0.9339567422866821\n",
            "28 60 91\n",
            "0.7077339887619019\n",
            "28 56 68\n",
            "0.78923100233078\n",
            "28 52 75\n",
            "0.8769189119338989\n",
            "28 52 69\n",
            "1.0563154220581055\n",
            "28 31 62\n",
            "0.862348198890686\n",
            "28 62 61\n",
            "1.0727614164352417\n",
            "28 62 114\n",
            "0.5899845361709595\n",
            "28 31 104\n",
            "0.8014844655990601\n",
            "28 31 65\n",
            "0.8857729434967041\n",
            "28 23 47\n",
            "0.7603680491447449\n",
            "28 38 50\n",
            "0.9442636966705322\n",
            "28 66 77\n",
            "0.8932983875274658\n",
            "28 66 69\n",
            "0.879930853843689\n",
            "28 66 98\n",
            "0.876270055770874\n",
            "29 34 80\n",
            "0.8183739185333252\n",
            "29 39 57\n",
            "0.7709602117538452\n",
            "29 39 56\n",
            "0.8914995193481445\n",
            "29 45 112\n",
            "0.7478015422821045\n",
            "29 54 105\n",
            "0.668911337852478\n",
            "29 54 66\n",
            "0.9784362316131592\n",
            "29 54 67\n",
            "0.8504335880279541\n",
            "29 35 83\n",
            "0.9225139617919922\n",
            "29 41 110\n",
            "0.7544984221458435\n",
            "29 41 46\n",
            "1.030125617980957\n",
            "29 55 59\n",
            "1.1242992877960205\n",
            "29 55 69\n",
            "0.6768382787704468\n",
            "29 44 65\n",
            "0.7362507581710815\n",
            "29 76 67\n",
            "1.0806688070297241\n",
            "29 76 50\n",
            "1.1233279705047607\n",
            "29 52 56\n",
            "0.8029319643974304\n",
            "29 52 71\n",
            "0.7893024682998657\n",
            "29 35 104\n",
            "0.7692031860351562\n",
            "29 78 115\n",
            "0.8305745720863342\n",
            "29 78 104\n",
            "0.8600993156433105\n",
            "29 45 81\n",
            "0.7959768176078796\n",
            "29 49 71\n",
            "0.7844141721725464\n",
            "29 49 47\n",
            "0.9252276420593262\n",
            "29 43 47\n",
            "0.8849151134490967\n",
            "29 84 114\n",
            "0.9291115999221802\n",
            "29 84 50\n",
            "1.020166039466858\n",
            "29 57 71\n",
            "0.760820746421814\n",
            "30 69 74\n",
            "0.8295547366142273\n",
            "30 69 79\n",
            "0.9615213871002197\n",
            "30 35 70\n",
            "0.8250001668930054\n",
            "30 35 75\n",
            "0.8538299798965454\n",
            "30 52 73\n",
            "0.7951810956001282\n",
            "30 52 82\n",
            "0.8887149095535278\n",
            "30 37 72\n",
            "0.6218091249465942\n",
            "30 36 56\n",
            "0.7073754668235779\n",
            "30 31 65\n",
            "0.9315893650054932\n",
            "30 32 57\n",
            "0.97803795337677\n",
            "30 32 99\n",
            "0.8858321309089661\n",
            "30 32 73\n",
            "0.7468796968460083\n",
            "30 35 126\n",
            "0.8641766309738159\n",
            "30 52 117\n",
            "0.8151748180389404\n",
            "30 52 65\n",
            "0.8298797011375427\n",
            "30 54 91\n",
            "0.842957079410553\n",
            "30 54 63\n",
            "0.7552315592765808\n",
            "30 39 50\n",
            "0.9945751428604126\n",
            "30 53 113\n",
            "0.8786447048187256\n",
            "30 53 88\n",
            "0.7438421249389648\n",
            "30 50 80\n",
            "0.8438393473625183\n",
            "30 79 123\n",
            "0.6915398836135864\n",
            "30 79 63\n",
            "0.7613310217857361\n",
            "30 41 101\n",
            "0.8031601905822754\n",
            "31 70 77\n",
            "0.7197723984718323\n",
            "31 70 49\n",
            "0.9554442763328552\n",
            "31 57 47\n",
            "1.1061794757843018\n",
            "31 32 76\n",
            "0.8873336315155029\n",
            "31 53 79\n",
            "0.9593381881713867\n",
            "31 53 95\n",
            "0.7347921133041382\n",
            "31 56 68\n",
            "1.02326500415802\n",
            "31 56 57\n",
            "0.8395416736602783\n",
            "31 55 67\n",
            "0.7107950448989868\n",
            "31 43 59\n",
            "0.8803545236587524\n",
            "31 78 60\n",
            "1.0441612005233765\n",
            "31 78 59\n",
            "0.8370031118392944\n",
            "31 78 72\n",
            "0.907049834728241\n",
            "31 48 72\n",
            "0.7539700865745544\n",
            "31 48 83\n",
            "0.9143636226654053\n",
            "31 39 79\n",
            "0.8473944067955017\n",
            "31 70 63\n",
            "0.8654612302780151\n",
            "31 70 70\n",
            "0.7955034971237183\n",
            "31 62 61\n",
            "1.0266066789627075\n",
            "31 59 67\n",
            "0.8843087553977966\n",
            "31 59 63\n",
            "0.8962485790252686\n",
            "31 61 133\n",
            "0.7990912199020386\n",
            "31 61 133\n",
            "0.810158371925354\n",
            "31 48 70\n",
            "0.8619069457054138\n",
            "31 48 74\n",
            "0.7098489999771118\n",
            "32 34 83\n",
            "0.6156314611434937\n",
            "32 55 65\n",
            "0.8008087873458862\n",
            "32 55 75\n",
            "0.866044282913208\n",
            "32 54 80\n",
            "0.9209648370742798\n",
            "32 54 66\n",
            "0.8125789165496826\n",
            "32 47 75\n",
            "0.563247561454773\n",
            "32 60 110\n",
            "0.6604025363922119\n",
            "32 60 50\n",
            "1.0641217231750488\n",
            "32 41 56\n",
            "0.6862260103225708\n",
            "32 67 79\n",
            "0.7231981754302979\n",
            "32 67 67\n",
            "0.8791266083717346\n",
            "32 58 67\n",
            "1.0024268627166748\n",
            "32 53 53\n",
            "0.9141242504119873\n",
            "32 40 59\n",
            "0.863821268081665\n",
            "32 60 72\n",
            "0.8563856482505798\n",
            "32 60 76\n",
            "0.773646354675293\n",
            "32 44 95\n",
            "0.7981040477752686\n",
            "32 88 110\n",
            "0.6528335809707642\n",
            "33 88 72\n",
            "0.8574588298797607\n",
            "33 50 60\n",
            "0.6365563869476318\n",
            "33 48 84\n",
            "0.689868688583374\n",
            "33 48 65\n",
            "0.6934255361557007\n",
            "33 53 75\n",
            "0.8610500693321228\n",
            "33 53 48\n",
            "0.9325411319732666\n",
            "33 47 114\n",
            "0.6992582082748413\n",
            "33 43 64\n",
            "0.7822582721710205\n",
            "33 43 57\n",
            "0.8375600576400757\n",
            "33 53 55\n",
            "0.9185296893119812\n",
            "33 53 63\n",
            "0.8495177626609802\n",
            "33 50 78\n",
            "0.6356533169746399\n",
            "33 50 79\n",
            "0.7625132203102112\n",
            "33 35 133\n",
            "0.592207133769989\n",
            "33 31 48\n",
            "0.7406682968139648\n",
            "33 40 60\n",
            "0.8971641659736633\n",
            "33 48 63\n",
            "1.0121545791625977\n",
            "33 48 77\n",
            "0.7395833730697632\n",
            "33 56 83\n",
            "0.6813510060310364\n",
            "33 56 61\n",
            "0.9102594256401062\n",
            "33 41 56\n",
            "0.7770411968231201\n",
            "33 48 70\n",
            "0.7546781897544861\n",
            "33 48 53\n",
            "0.8368297815322876\n",
            "33 48 64\n",
            "0.8923441171646118\n",
            "33 47 72\n",
            "0.9389541149139404\n",
            "33 47 92\n",
            "0.7551321983337402\n",
            "34 47 60\n",
            "0.8608012199401855\n",
            "34 42 74\n",
            "0.632645308971405\n",
            "34 33 64\n",
            "0.8041249513626099\n",
            "34 55 56\n",
            "0.9478629231452942\n",
            "34 55 121\n",
            "0.6744548082351685\n",
            "34 58 76\n",
            "0.8454996347427368\n",
            "34 65 85\n",
            "0.995888352394104\n",
            "34 65 46\n",
            "0.8222609162330627\n",
            "34 53 119\n",
            "0.6668006181716919\n",
            "34 39 70\n",
            "1.0348081588745117\n",
            "34 66 60\n",
            "0.8600956201553345\n",
            "34 66 61\n",
            "0.9253098964691162\n",
            "34 40 114\n",
            "0.7941833734512329\n",
            "34 62 50\n",
            "1.0124950408935547\n",
            "34 62 58\n",
            "0.8972502946853638\n",
            "34 48 83\n",
            "0.7639504671096802\n",
            "34 48 58\n",
            "0.8879795670509338\n",
            "34 61 50\n",
            "1.2662259340286255\n",
            "34 61 64\n",
            "0.8322845101356506\n",
            "34 28 67\n",
            "0.6669118404388428\n",
            "34 49 68\n",
            "0.89519202709198\n",
            "34 49 133\n",
            "0.784844160079956\n",
            "34 47 63\n",
            "0.7460253834724426\n",
            "35 44 59\n",
            "0.8457516431808472\n",
            "35 32 41\n",
            "0.8520985841751099\n",
            "35 34 71\n",
            "0.6522145867347717\n",
            "35 34 52\n",
            "0.8303253650665283\n",
            "35 33 98\n",
            "0.40941816568374634\n",
            "35 45 128\n",
            "0.7040213346481323\n",
            "35 61 98\n",
            "0.723397433757782\n",
            "35 61 74\n",
            "0.7340011596679688\n",
            "35 47 53\n",
            "0.8408190011978149\n",
            "35 125 72\n",
            "0.9292783737182617\n",
            "35 125 83\n",
            "0.9472637176513672\n",
            "35 79 68\n",
            "0.9990058541297913\n",
            "35 36 64\n",
            "0.7548149228096008\n",
            "35 43 105\n",
            "0.6375095248222351\n",
            "35 43 76\n",
            "0.7647473812103271\n",
            "35 47 91\n",
            "0.7936719655990601\n",
            "35 50 115\n",
            "0.6741902232170105\n",
            "35 50 65\n",
            "0.8922079205513\n",
            "35 19 72\n",
            "0.7882643938064575\n",
            "35 51 64\n",
            "0.9233611226081848\n",
            "35 40 93\n",
            "0.7173471450805664\n",
            "35 44 141\n",
            "0.7001546025276184\n",
            "35 44 63\n",
            "0.7263707518577576\n",
            "35 46 58\n",
            "1.0701477527618408\n",
            "30 27 69\n",
            "1.1346511840820312\n",
            "30 78 71\n",
            "0.9904704093933105\n",
            "30 78 94\n",
            "1.0752207040786743\n",
            "30 24 99\n",
            "0.6720558404922485\n",
            "30 31 56\n",
            "0.8478788137435913\n",
            "30 32 56\n",
            "0.9768730401992798\n",
            "30 49 65\n",
            "1.0817574262619019\n",
            "30 49 52\n",
            "1.0718146562576294\n",
            "30 41 97\n",
            "0.9358747005462646\n",
            "30 31 60\n",
            "0.8274827003479004\n",
            "30 49 105\n",
            "0.9249421954154968\n",
            "30 49 44\n",
            "1.0403095483779907\n",
            "30 48 74\n",
            "0.7513930797576904\n",
            "30 30 57\n",
            "0.8625856637954712\n",
            "30 36 69\n",
            "0.8640686869621277\n",
            "30 37 112\n",
            "0.957521915435791\n",
            "30 51 94\n",
            "0.7575626373291016\n",
            "30 51 74\n",
            "1.234352469444275\n",
            "30 51 81\n",
            "0.9208167791366577\n",
            "30 43 91\n",
            "0.6872496604919434\n",
            "30 38 100\n",
            "0.7654544115066528\n",
            "30 37 74\n",
            "0.7917256951332092\n",
            "30 37 94\n",
            "0.8360253572463989\n",
            "30 61 67\n",
            "0.904879093170166\n",
            "30 61 85\n",
            "0.9533658027648926\n",
            "30 39 114\n",
            "0.700064480304718\n",
            "30 44 63\n",
            "0.8881628513336182\n",
            "30 63 64\n",
            "0.9647352695465088\n",
            "30 63 60\n",
            "0.9320286512374878\n",
            "30 68 74\n",
            "0.8334730267524719\n",
            "30 68 78\n",
            "0.8730562329292297\n",
            "30 58 104\n",
            "1.0225834846496582\n",
            "30 69 83\n",
            "0.5675085783004761\n",
            "30 69 71\n",
            "0.8487756252288818\n",
            "30 37 55\n",
            "0.9628523588180542\n",
            "30 52 114\n",
            "1.0146241188049316\n",
            "30 52 85\n",
            "0.9401073455810547\n",
            "30 42 117\n",
            "0.7162676453590393\n",
            "30 39 105\n",
            "0.6740337610244751\n",
            "30 55 61\n",
            "0.9981915950775146\n",
            "30 55 63\n",
            "1.065364122390747\n",
            "30 40 63\n",
            "0.8682012557983398\n",
            "30 41 61\n",
            "0.6786566376686096\n",
            "30 53 110\n",
            "0.6162649989128113\n",
            "30 53 98\n",
            "0.7494335770606995\n",
            "30 50 71\n",
            "0.8213242292404175\n",
            "30 40 79\n",
            "0.8260071873664856\n",
            "30 34 59\n",
            "0.7915635704994202\n",
            "30 41 60\n",
            "0.8774498701095581\n",
            "30 47 73\n",
            "0.7024887800216675\n",
            "30 22 72\n",
            "0.9819879531860352\n",
            "30 47 88\n",
            "0.7138558626174927\n",
            "30 47 81\n",
            "0.8067559599876404\n",
            "30 40 81\n",
            "0.7127454280853271\n",
            "30 50 99\n",
            "0.5998353958129883\n",
            "30 50 97\n",
            "0.7264206409454346\n",
            "30 66 122\n",
            "1.0484836101531982\n",
            "30 47 66\n",
            "0.9453563094139099\n",
            "30 39 99\n",
            "0.6873860359191895\n",
            "30 30 69\n",
            "0.9182429313659668\n",
            "30 50 70\n",
            "0.9552753567695618\n",
            "30 70 54\n",
            "0.9184653162956238\n",
            "30 92 79\n",
            "1.010721206665039\n",
            "30 47 114\n",
            "0.7730429768562317\n",
            "30 46 102\n",
            "0.8815499544143677\n",
            "30 105 133\n",
            "0.8324301242828369\n",
            "30 105 69\n",
            "0.9158768057823181\n",
            "30 76 99\n",
            "1.0739655494689941\n",
            "30 53 55\n",
            "0.9547735452651978\n",
            "30 53 69\n",
            "0.9085583090782166\n",
            "30 54 53\n",
            "0.9402667284011841\n",
            "30 54 50\n",
            "1.1177151203155518\n",
            "30 54 49\n",
            "0.9614198207855225\n",
            "30 30 81\n",
            "0.9095715284347534\n",
            "30 51 78\n",
            "0.8493516445159912\n",
            "30 51 63\n",
            "0.7324033975601196\n",
            "30 44 59\n",
            "0.9032559394836426\n",
            "30 40 55\n",
            "0.8899859189987183\n",
            "30 40 117\n",
            "0.9429330825805664\n",
            "30 46 53\n",
            "0.8890846967697144\n",
            "30 46 69\n",
            "0.6501929759979248\n",
            "30 44 117\n",
            "0.7845876216888428\n",
            "30 39 67\n",
            "0.8494886159896851\n",
            "30 60 80\n",
            "0.7577122449874878\n",
            "30 60 164\n",
            "0.8989320993423462\n",
            "30 31 75\n",
            "0.8252739906311035\n",
            "30 56 110\n",
            "0.7574590444564819\n",
            "30 56 55\n",
            "0.7698200941085815\n",
            "30 33 57\n",
            "0.8514277338981628\n",
            "30 41 104\n",
            "0.7540204524993896\n",
            "30 41 80\n",
            "0.864033579826355\n",
            "30 43 85\n",
            "1.1390025615692139\n",
            "30 57 89\n",
            "0.8236531615257263\n",
            "30 57 73\n",
            "0.7486194372177124\n",
            "30 44 88\n",
            "0.6669790744781494\n",
            "30 38 97\n",
            "1.0916142463684082\n",
            "30 33 41\n",
            "0.9487584829330444\n",
            "30 33 87\n",
            "0.6589328050613403\n",
            "30 42 94\n",
            "1.0442782640457153\n",
            "30 42 79\n",
            "0.8871524333953857\n",
            "30 34 63\n",
            "0.7476538419723511\n",
            "30 30 56\n",
            "0.6015509963035583\n",
            "30 50 66\n",
            "0.9654179811477661\n",
            "30 50 92\n",
            "0.881193995475769\n",
            "30 47 67\n",
            "0.9404374957084656\n",
            "30 65 113\n",
            "0.7962504029273987\n",
            "30 65 110\n",
            "1.050311803817749\n",
            "30 59 75\n",
            "0.9665447473526001\n",
            "30 31 69\n",
            "0.7497732043266296\n",
            "30 55 54\n",
            "0.960874080657959\n",
            "30 55 50\n",
            "0.8675448894500732\n",
            "30 32 58\n",
            "0.7843228578567505\n",
            "30 58 133\n",
            "0.7240979671478271\n",
            "30 49 59\n",
            "1.1295183897018433\n",
            "30 52 71\n",
            "0.9067956209182739\n",
            "30 69 66\n",
            "0.9740414619445801\n",
            "30 69 79\n",
            "1.1286258697509766\n",
            "30 60 68\n",
            "0.990368664264679\n",
            "30 32 46\n",
            "1.021602988243103\n",
            "30 56 96\n",
            "0.7810714840888977\n",
            "30 69 54\n",
            "1.1294056177139282\n",
            "30 69 52\n",
            "1.114088773727417\n",
            "30 41 63\n",
            "0.9935942888259888\n",
            "30 37 105\n",
            "0.6785024404525757\n",
            "30 49 65\n",
            "1.0029029846191406\n",
            "30 49 56\n",
            "0.8751921653747559\n",
            "30 49 62\n",
            "0.9238895177841187\n",
            "30 49 71\n",
            "0.7773373126983643\n",
            "30 35 59\n",
            "0.9313065409660339\n",
            "30 53 91\n",
            "0.9423577785491943\n",
            "30 53 114\n",
            "0.7939063310623169\n",
            "30 36 64\n",
            "0.8564342856407166\n",
            "30 36 60\n",
            "0.9614103436470032\n",
            "30 43 65\n",
            "0.8728946447372437\n",
            "30 43 56\n",
            "0.7408883571624756\n",
            "30 42 53\n",
            "0.77250075340271\n",
            "30 59 121\n",
            "0.7949538826942444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9832597417a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m               torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMarginRankingLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-35a79c969775>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_iter, optimizer, criterion, clip, N_EPOCH)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-972e918310ea>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_iter, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mhistory_rpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrue_rpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mfalse_rpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m## rpr = [batch_size, hidden]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPairwiseDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-8662b3c71052>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtemp_pos_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             output = self.layers[i](output, src_mask=mask,\n\u001b[0;32m--> 176\u001b[0;31m                                     src_key_padding_mask=src_key_padding_mask)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \"\"\"\n\u001b[1;32m    282\u001b[0m         src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n\u001b[0;32m--> 283\u001b[0;31m                               key_padding_mask=src_key_padding_mask)[0]\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   3195\u001b[0m     \"\"\"\n\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3197\u001b[0;31m     \u001b[0mqkv_same\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3198\u001b[0m     \u001b[0mkv_same\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/THCReduceAll.cuh:327"
          ]
        }
      ]
    }
  ]
}